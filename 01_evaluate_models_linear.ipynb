{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33092622-3ffc-444a-871d-12bad5085a76",
   "metadata": {},
   "source": [
    "# Create linear prompts and evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eedd0538-21b6-4d6e-84f2-c3d705716942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "import os.path\n",
    "\n",
    "from LinearGraphGenerator import *\n",
    "from ModelFunctions import *\n",
    "\n",
    "# Increase resolution of plots\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['figure.figsize'] = [15, 7]\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398ab580-4ff2-4272-ac62-92f5dfa71c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI models\n",
    "GPT_model = 'gpt-4o-mini'\n",
    "# GPT_model = 'gpt-4o'\n",
    "# GPT_model = 'o1-preview'\n",
    "\n",
    "#Anthropic models\n",
    "anthropic_model = 'claude-3-5-haiku-latest'\n",
    "# anthropic_model = 'claude-3-5-sonnet-latest'\n",
    "\n",
    "#Google models\n",
    "google_model = \"gemini-1.5-flash\"\n",
    "# google_model = \"gemini-1.5-pro\"\n",
    "\n",
    "all_models = ['gpt-4o-mini', 'gpt-4o', 'o1-preview', 'claude-3-5-sonnet-latest', 'claude-3-5-haiku-latest', \"gemini-1.5-flash\", \"gemini-1.5-pro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9896083-3c15-4225-90b0-f8338e5b602a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case with 2 arguments and the following prompt:\n",
       "###\n",
       "The following is a reasoning puzzle. Witnesses should be believed unless there is testimony that they are lying. Now consider the following facts:\n",
       "Witness Etta says that the plane is landing.\n",
       "Witness Zuri says that witness Etta is lying.\n",
       "Question: should it be believed that the plane is landing?\n",
       "End your answer with: \"Answer: yes or no\"\n",
       "###\n",
       "\n",
       "Answer: False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the caseGenerator\n",
    "gen = CaseGenerator(shuffle_arguments=False)\n",
    "c = gen.generate_case(2)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5edaa7-bcbb-48e6-ab06-c27ad4a2455b",
   "metadata": {},
   "source": [
    "### Create a temporary static benchmark for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44f3ffc-e1db-45e2-a5d2-cfdd39c09835",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_variations = 100 # Num ontological variations\n",
    "min_args = 1 # Minimum number of arguments in graph\n",
    "max_args = 25 # Maxmimum number of arguments in graph\n",
    "shuffle = False # whether to shuffle the arguments\n",
    "run = '' #Identifier\n",
    "\n",
    "df = []\n",
    "gen = CaseGenerator(shuffle_arguments=shuffle)\n",
    "for iter_x in range(0, num_variations):\n",
    "    for num_args in range(min_args, max_args+1):\n",
    "        c = gen.generate_case(num_args)\n",
    "        case = {\n",
    "            'id': str(iter_x) + '_' + str(c.num_arguments),\n",
    "            'num_args' : c.num_arguments,\n",
    "            'prompt' : c.prompt,\n",
    "            'answer' : c.answer,\n",
    "         }\n",
    "        df.append(case)\n",
    "pd.DataFrame(df).to_csv('static_benchmarks/static_linear_'+str(num_variations)+'_'+str(max_args)+'_shuffle_'+str(shuffle)+run+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dcfbf3-016c-458f-8436-83bbd29795f0",
   "metadata": {},
   "source": [
    "## Make calls to LLM and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d29cbb-49ab-4e38-88da-0a50b17509cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_args</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_1</td>\n",
       "      <td>1</td>\n",
       "      <td>The following is a reasoning puzzle. Witnesses...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_2</td>\n",
       "      <td>2</td>\n",
       "      <td>The following is a reasoning puzzle. Witnesses...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_3</td>\n",
       "      <td>3</td>\n",
       "      <td>The following is a reasoning puzzle. Witnesses...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_4</td>\n",
       "      <td>4</td>\n",
       "      <td>The following is a reasoning puzzle. Witnesses...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_5</td>\n",
       "      <td>5</td>\n",
       "      <td>The following is a reasoning puzzle. Witnesses...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>99_21</td>\n",
       "      <td>21</td>\n",
       "      <td>The following is a reasoning puzzle. Witnesses...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>99_22</td>\n",
       "      <td>22</td>\n",
       "      <td>The following is a reasoning puzzle. Witnesses...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>99_23</td>\n",
       "      <td>23</td>\n",
       "      <td>The following is a reasoning puzzle. Witnesses...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>99_24</td>\n",
       "      <td>24</td>\n",
       "      <td>The following is a reasoning puzzle. Witnesses...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>99_25</td>\n",
       "      <td>25</td>\n",
       "      <td>The following is a reasoning puzzle. Witnesses...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  num_args                                             prompt  \\\n",
       "0       0_1         1  The following is a reasoning puzzle. Witnesses...   \n",
       "1       0_2         2  The following is a reasoning puzzle. Witnesses...   \n",
       "2       0_3         3  The following is a reasoning puzzle. Witnesses...   \n",
       "3       0_4         4  The following is a reasoning puzzle. Witnesses...   \n",
       "4       0_5         5  The following is a reasoning puzzle. Witnesses...   \n",
       "...     ...       ...                                                ...   \n",
       "2495  99_21        21  The following is a reasoning puzzle. Witnesses...   \n",
       "2496  99_22        22  The following is a reasoning puzzle. Witnesses...   \n",
       "2497  99_23        23  The following is a reasoning puzzle. Witnesses...   \n",
       "2498  99_24        24  The following is a reasoning puzzle. Witnesses...   \n",
       "2499  99_25        25  The following is a reasoning puzzle. Witnesses...   \n",
       "\n",
       "      answer  \n",
       "0          1  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  \n",
       "...      ...  \n",
       "2495       1  \n",
       "2496       0  \n",
       "2497       1  \n",
       "2498       0  \n",
       "2499       1  \n",
       "\n",
       "[2500 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_df = pd.read_csv('static_benchmarks/static_linear_100_25_shuffle_False.csv')\n",
    "case_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7f3a63-5f17-4ea6-bc03-3bb9dbb1f0eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: dummy\n",
      "(2500/2500) 100.0% ETA:0:0:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run = '_linear'\n",
    "result_df = []\n",
    "\n",
    "all_models = ['gpt-4o-mini', 'gpt-4o', 'o1-preview', 'claude-3-5-sonnet-latest', 'claude-3-5-haiku-latest', \"gemini-1.5-flash\", \"gemini-1.5-pro\"]\n",
    "model = 'dummy' # Replace this\n",
    "all_models = ['dummy']\n",
    "\n",
    "for model in all_models:\n",
    "    print('Model:', model)\n",
    "    filename = 'results/'+model.replace('.', '') + run + '.csv'\n",
    "    current_id = 0\n",
    "    \n",
    "    start_time = monotonic()\n",
    "    for idx, case in case_df.iloc[current_id:].iterrows():\n",
    "        iteration = int(case['id'].split('_')[0])\n",
    "        print_status(idx, len(case_df), current_id, start_time)\n",
    "        c = Case(case['num_args'], case['prompt'], case['answer'])\n",
    "        result = make_llm_call(c.prompt, model=model)\n",
    "        write_csv(filename, {\n",
    "            'iteration': iteration,\n",
    "            'num_args': c.num_arguments,\n",
    "            'prompt': c.prompt,\n",
    "            'full_response': result,\n",
    "            'processed_response': process_answer(result),\n",
    "            'correct_answer': c.answer,\n",
    "        })\n",
    "    print_status(idx+1, len(case_df), current_id, start_time)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
